{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e5a098",
   "metadata": {},
   "source": [
    "# This is a full pipeline with keypoints prediction using VAE in reconstruction mode for VoxCeleb dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4af7e9",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afa4a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Training_Prediction.FOMM.Source_Model.logger import Logger, Visualizer\n",
    "import numpy as np\n",
    "import imageio\n",
    "from Training_Prediction.FOMM.Source_Model.sync_batchnorm import DataParallelWithCallback\n",
    "from Training_Prediction.PREDICTOR.VAE import VAE_origin\n",
    "from Training_Prediction.FOMM.Source_Model.augmentation import SelectRandomFrames, SelectFirstFrames_two, VideoToTensor\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from Training_Prediction.FOMM.Source_Model.frames_dataset import FramesDataset\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pickle\n",
    "from Training_Prediction.PREDICTOR.Source_Model.prediction_toplevel import KPDataset,get_data_from_dataloader_60\n",
    "import gc\n",
    "import pickle\n",
    "import yaml\n",
    "from Training_Prediction.FOMM.Source_Model.modules.generator import OcclusionAwareGenerator,calculate_frechet_distance,compute_fvd\n",
    "from Training_Prediction.FOMM.Source_Model.modules.keypoint_detector import KPDetector\n",
    "from Training_Prediction.FOMM.Source_Model.logger import Logger, Visualizer, Visualizer_slow\n",
    "from torch import nn\n",
    "import tensorflow.compat.v1 as tf\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import vmaf\n",
    "import subprocess\n",
    "import imageio\n",
    "import json\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8915fe4-5e75-4773-8495-a34bbea2ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_as_png(frames, png_dir):\n",
    "    for idx, frame in enumerate(frames):\n",
    "        frame_path = os.path.join(png_dir, f'video_frame_{idx:04d}.png')\n",
    "        imageio.imsave(frame_path, (255 * frame).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc7cf7d3-18db-4f9a-bb32-ba513cf73090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_png_to_mp4(png_dir,mp4_dir,video_number):\n",
    "    if not png_dir.endswith('/'):\n",
    "        png_dir += '/'\n",
    "    if not mp4_dir.endswith('/'):\n",
    "        mp4_dir += '/'\n",
    "    \n",
    "    input_pattern = f\"{png_dir}video_frame_%04d.png\"\n",
    "    output_file = f\"{mp4_dir}video_{video_number:02d}.mp4\"\n",
    "    command = (f'ffmpeg -y -r 60 -i {png_dir}/video_frame_%04d.png -pix_fmt yuv420p -profile:v high -level:v 4.1 -crf:v 20 -movflags +faststart {mp4_dir}/video_{video_number:02d}.mp4')\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68291432-b39e-4d3d-b199-e7c2799d982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_png_to_y4m(png_dir, y4m_dir, video_number):\n",
    "    if not png_dir.endswith('/'):\n",
    "        png_dir += '/'\n",
    "    if not y4m_dir.endswith('/'):\n",
    "        y4m_dir += '/'\n",
    "    \n",
    "    input_pattern = f\"{png_dir}video_frame_%04d.png\"\n",
    "    output_file = f\"{y4m_dir}video_{video_number:02d}.y4m\"\n",
    "    \n",
    "    command = (f'ffmpeg -y -i {input_pattern} -r 24 -pix_fmt yuv444p {output_file}')    \n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99b12791-2ab7-410e-bc58-304a1ffebeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vmaf(driving_vid, generated_vid, output_path):\n",
    "    if driving_vid[-3:] != 'y4m':\n",
    "         raise Exception('Video must be in y4m format.')\n",
    "    if generated_vid[-3:] != 'y4m':\n",
    "         raise Exception('Video must be in y4m format.')\n",
    "    if output_path[-4:] != 'json':\n",
    "        raise Exception('Output file must be in json format')\n",
    "    \n",
    "    command = (f'vmaf --reference {driving_vid} --distorted {generated_vid} --model version=vmaf_v0.6.1 --output {output_path} --json')\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d131c",
   "metadata": {},
   "source": [
    "# Define VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cc260a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_time = 12\n",
    "\n",
    "\n",
    "model = VAE_origin(60, lag_time=lag_time,\n",
    "          hidden_size=256, hidden_layer_depth=3,\n",
    "          batch_size=250, n_epochs=100, cuda=True, \n",
    "          sliding_window=True, dropout_rate=0.3,\n",
    "          learning_rate=1E-3, scale=1E-3, autocorr=False, encoder_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f25b2a",
   "metadata": {},
   "source": [
    "# After VAE is trained, load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b6477d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VDE(input_size=60, encoder_size=20, n_epochs=100,\n",
       "    batch_size=250, lag_time=12, sliding_window=True,\n",
       "    autocorr=False, cuda=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Checkpoints/VAE_3883videos_vox_12-12.pth')) # 12-12 frames\n",
    "# model.load_state_dict(torch.load('Checkpoints/VAE_3883videos_vox_6-6.pth')) # 6-6 frames\n",
    "\n",
    "# Set the model to evaluation mode (important if using dropout or batch normalization)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67981bd7",
   "metadata": {},
   "source": [
    "# Import keypoints of 44 VoxCeleb test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90335bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"kp_test_44_vox.pkl\", \"rb\") as f:\n",
    "    kp_time_series = pickle.load(f)\n",
    "len(kp_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7088199",
   "metadata": {},
   "source": [
    "# Convert list of keypoints to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebeed979",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_idx in range(len(kp_time_series)):\n",
    "    kp_time_series[video_idx] = kp_time_series[video_idx]['kp']\n",
    "\n",
    "kp_dict_init = []\n",
    "for video_idx in range(len(kp_time_series)): # \n",
    "    init_mean = []\n",
    "    init_jacobian = []\n",
    "    for frame_idx in range(len(kp_time_series[video_idx])):\n",
    "        kp_mean = kp_time_series[video_idx][frame_idx]['value'].reshape(1,10,2)\n",
    "        kp_mean = torch.tensor(kp_mean)\n",
    "        kp_jacobian = kp_time_series[video_idx][frame_idx]['jacobian'].reshape(1,10,2,2)\n",
    "        kp_jacobian = torch.tensor(kp_jacobian)\n",
    "\n",
    "        init_mean.append(kp_mean)\n",
    "        init_jacobian.append(kp_jacobian)\n",
    "\n",
    "    init_mean = torch.cat(init_mean)\n",
    "    init_jacobian = torch.cat(init_jacobian)\n",
    "\n",
    "    init_mean = torch.reshape(init_mean,(1,init_mean.shape[0],init_mean.shape[1],init_mean.shape[2]))\n",
    "    init_jacobian = torch.reshape(init_jacobian,(1,init_jacobian.shape[0],10,2,2))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # add tensor to cuda\n",
    "        init_mean = init_mean.to('cuda:0')\n",
    "        init_jacobian = init_jacobian.to('cuda:0')\n",
    "\n",
    "    kp_dict_both = {\"value\":init_mean,\"jacobian\":init_jacobian}\n",
    "    kp_dict_init.append(kp_dict_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46fe1b",
   "metadata": {},
   "source": [
    "# Apply min-max std to keypoints and convert to batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2333a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "(118, 60)\n"
     ]
    }
   ],
   "source": [
    "kp_list_test = []\n",
    "for video_idx in range(len(kp_dict_init)):\n",
    "    kp_one_video = torch.cat((kp_dict_init[video_idx]['value'], kp_dict_init[video_idx]['jacobian'].reshape(1,-1,10,4)),dim=-1).reshape(-1,60)\n",
    "    kp_one_video_array = np.array(kp_one_video.cpu())\n",
    "    kp_list_test.append(kp_one_video_array)\n",
    "    \n",
    "#####  min-max std to 60 dimensions of selected one video ######\n",
    "kp_list_test_std = []\n",
    "min_list = []\n",
    "range_list = []\n",
    "for video_idx in range(len(kp_list_test)):\n",
    "    data = kp_list_test[video_idx]\n",
    "    data_length = len(kp_list_test[video_idx])\n",
    "    step_interval = 12 # choose between 12 frames or 24 frames \n",
    "    min_required_steps = 2*step_interval\n",
    "    selected_data = []\n",
    "    for i in range(0, data_length - min_required_steps+1, 2 * step_interval):\n",
    "        selected_data.extend(data[i:i + step_interval])\n",
    "    min_values = np.min(selected_data,axis=0) # 60 mins of one selected video in the loop\n",
    "    max_values = np.max(selected_data,axis=0) # 60 maxs of one selected video in the loop \n",
    "    range_values = max_values - min_values \n",
    "    kp_one_video_std = (kp_list_test[video_idx] - min_values) / range_values\n",
    "    kp_list_test_std.append(kp_one_video_std)\n",
    "    min_list.append(min_values)\n",
    "    range_list.append(range_values)\n",
    "\n",
    "trajs = kp_list_test_std\n",
    "print(len(trajs))\n",
    "print(trajs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad330665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset batches: 529\n",
      "(24, 60)\n"
     ]
    }
   ],
   "source": [
    "######### convert into batches:\n",
    "frames = min_required_steps\n",
    "input_frames = int(frames / 2)\n",
    "data_batch_test = []\n",
    "for t,x in enumerate(kp_list_test_std):\n",
    "    if x.shape[0] >= frames:\n",
    "        num_full_batches = x.shape[0] // frames\n",
    "        for arr in np.array_split(x[:num_full_batches * frames], num_full_batches):\n",
    "            data_batch_test.append(arr)\n",
    "print(f'test dataset batches:', len(data_batch_test))\n",
    "print(data_batch_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eff75c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 24, 60)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### test dataset:\n",
    "\n",
    "test_data_reshape = np.array(data_batch_test).reshape(-1,frames,60)\n",
    "test_data_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c19e5-ee36-44cc-a8c7-7caff90e7d29",
   "metadata": {},
   "source": [
    "# Predict keypoints using trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20c9c688-c031-4a26-8a24-2720d2b21e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([529, 12, 60])\n",
      "torch.Size([529, 12, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6337/207256912.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_input = torch.tensor(validation_input).to(device)\n"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "validation_data = test_data_reshape\n",
    "\n",
    "# evaluate model:\n",
    "validation_input = torch.tensor(validation_data[:,:input_frames], dtype = torch.float32) # input: [24,10,17]\n",
    "kp_gt = torch.tensor(validation_data[:,input_frames:], dtype = torch.float32) # gtoundtruth: [24,10,17]\n",
    "\n",
    "# Move the model to the desired device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Check the device of your input tensor (x)\n",
    "validation_input = torch.tensor(validation_input).to(device)\n",
    "\n",
    "pred_encoded = model.encoder(validation_input)\n",
    "pred_lmbd = model.lmbd(pred_encoded)\n",
    "pred = model.decoder(pred_lmbd)\n",
    "\n",
    "print(kp_gt.shape)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b86c4-b761-48d9-ad9a-88908129633b",
   "metadata": {},
   "source": [
    "# Generate unstd keypoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd71d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches of each video: 44\n"
     ]
    }
   ],
   "source": [
    "# save num_batches for each video:\n",
    "num_batch_video = []\n",
    "num_full_batches_all = 0\n",
    "for t,x in enumerate(kp_list_test_std):\n",
    "    if x.shape[0] > frames:\n",
    "        num_full_batches = x.shape[0] // frames\n",
    "        num_full_batches_all += num_full_batches\n",
    "        num_batch_video.append(num_full_batches)\n",
    "print(f'number of batches of each video:', len(num_batch_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dacf886e-0203-4086-bedb-4468e1cf4fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 24, 60)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first half of frames: groundtruth; last half of frames: predicted\n",
    "test_gt_pred = np.concatenate((test_data_reshape[:,:input_frames], pred.detach().cpu()), axis = 1)\n",
    "\n",
    "test_gt_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f220aff-17ab-43e2-a335-3b54857cc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for no prediction\n",
    "test_video_unstd_list = kp_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e56be0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstd for each video -- for prediction\n",
    "test_video_unstd_list = []\n",
    "for video_idx in range(len(num_batch_video)):\n",
    "    test_video = test_gt_pred[sum(num_batch_video[:video_idx]):sum(num_batch_video[:video_idx+1])]\n",
    "    test_video_unstd = test_video * range_list[video_idx] + min_list[video_idx]\n",
    "    test_video_unstd_list.append(test_video_unstd) # unstd video keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74a397-20c6-4395-b7b9-c14de9621770",
   "metadata": {},
   "source": [
    "# Optical flow and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fee04637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n",
      "using videos from test directory\n",
      "['id10280#NXjT3732Ekg#001093#001192.mp4', 'id10281#NHARUN9OhSo#000605#000886.mp4', 'id10281#NHARUN9OhSo#001059#001210.mp4', 'id10281#NHARUN9OhSo#002098#002175.mp4', 'id10281#NHARUN9OhSo#002209#002570.mp4', 'id10281#NHARUN9OhSo#006609#006906.mp4', 'id10281#NHARUN9OhSo#006912#007284.mp4', 'id10281#NHARUN9OhSo#007425#007663.mp4', 'id10282#IDA_ElNHLn4#000674#000852.mp4', 'id10282#IDA_ElNHLn4#001226#001390.mp4', 'id10283#N69Hp2DGMLk#000519#000619.mp4', 'id10283#N69Hp2DGMLk#000721#000842.mp4', 'id10283#N69Hp2DGMLk#000893#001589.mp4', 'id10283#N69Hp2DGMLk#004133#005157.mp4', 'id10283#N69Hp2DGMLk#005157#005316.mp4', 'id10283#N69Hp2DGMLk#005931#006184.mp4', 'id10283#N69Hp2DGMLk#006184#006353.mp4', 'id10283#N69Hp2DGMLk#006405#006583.mp4', 'id10283#N69Hp2DGMLk#006600#007118.mp4', 'id10283#N69Hp2DGMLk#007129#007281.mp4', 'id10283#r9-0pljhZqs#002414#002769.mp4', 'id10283#r9-0pljhZqs#003725#003847.mp4', 'id10283#r9-0pljhZqs#004062#004408.mp4', 'id10283#r9-0pljhZqs#007271#007498.mp4', 'id10283#r9-0pljhZqs#007920#008172.mp4', 'id10283#r9-0pljhZqs#008373#008488.mp4', 'id10283#r9-0pljhZqs#009636#009808.mp4', 'id10283#r9-0pljhZqs#010121#010605.mp4', 'id10283#r9-0pljhZqs#010765#010954.mp4', 'id10283#r9-0pljhZqs#011158#011299.mp4', 'id10283#r9-0pljhZqs#012307#012561.mp4', 'id10283#r9-0pljhZqs#013264#013592.mp4', 'id10283#r9-0pljhZqs#013743#013963.mp4', 'id10283#r9-0pljhZqs#014353#014609.mp4', 'id10283#r9-0pljhZqs#014722#014831.mp4', 'id10283#r9-0pljhZqs#014864#015079.mp4', 'id10283#r9-0pljhZqs#015364#015539.mp4', 'id10283#rUnfAxF1dJI#001389#001843.mp4', 'id10283#uA1E_38TuTw#001699#001863.mp4', 'id10283#uA1E_38TuTw#002329#002480.mp4', 'id10283#uA1E_38TuTw#002875#002990.mp4', 'id10283#uA1E_38TuTw#003095#003227.mp4', 'id10283#uA1E_38TuTw#003246#003371.mp4', 'id10283#x6M3KQ8-gM4#000018#000441.mp4']\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "####### call the config functions and inference dataloader #########\n",
    "config=\"config/abs-vox.yml\"\n",
    "\n",
    "# Test dataset\n",
    "with open(config) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "dataset = FramesDataset(is_train=(False), **config['dataset_params'],mode=\"RNN\") # test\n",
    "\n",
    "print(len(dataset))\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "### call the functions        \n",
    "generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n",
    "                                        **config['model_params']['common_params'])\n",
    "kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
    "                            **config['model_params']['common_params'])\n",
    "\n",
    "log_dir=\"./log/test-reconstruction-vox\"\n",
    "checkpoint=\"./Training_Prediction/FOMM/Trained_Models/vox-cpk.pth.tar\"\n",
    "\n",
    "if checkpoint is not None:\n",
    "    Logger.load_cpk(checkpoint, generator=generator, kp_detector=kp_detector)\n",
    "else:\n",
    "    raise AttributeError(\"Checkpoint should be specified for mode='reconstruction'.\")\n",
    "    \n",
    "def save_obj(obj, name ):\n",
    "    with open('./'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('./' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "pred_png_dir = os.path.join(log_dir, 'prediction/prediction_png')\n",
    "pred_mp4_dir = os.path.join(log_dir, 'prediction/prediction_mp4')\n",
    "pred_y4m_dir = os.path.join(log_dir, 'prediction/prediction_y4m')\n",
    "driving_png_dir = os.path.join(log_dir, 'prediction/driving_png')\n",
    "driving_mp4_dir = os.path.join(log_dir, 'prediction/driving_mp4')\n",
    "driving_y4m_dir = os.path.join(log_dir, 'prediction/driving_y4m')\n",
    "vae_vmaf_output = os.path.join(log_dir, 'prediction/vmaf_json_output_vae')\n",
    "\n",
    "log_dir = os.path.join(log_dir, 'prediction')\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "if not os.path.exists(pred_png_dir):\n",
    "    os.makedirs(pred_png_dir)\n",
    "if not os.path.exists(pred_mp4_dir):\n",
    "    os.makedirs(pred_mp4_dir)\n",
    "if not os.path.exists(pred_y4m_dir):\n",
    "    os.makedirs(pred_y4m_dir)\n",
    "\n",
    "if not os.path.exists(driving_png_dir):\n",
    "    os.makedirs(driving_png_dir)\n",
    "if not os.path.exists(driving_mp4_dir):\n",
    "    os.makedirs(driving_mp4_dir)\n",
    "if not os.path.exists(driving_y4m_dir):\n",
    "    os.makedirs(driving_y4m_dir)\n",
    "\n",
    "if not os.path.exists(vae_vmaf_output):\n",
    "    os.makedirs(vae_vmaf_output)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = DataParallelWithCallback(generator)\n",
    "    kp_detector = DataParallelWithCallback(kp_detector)\n",
    "\n",
    "generator.eval()\n",
    "kp_detector.eval()\n",
    "\n",
    "prediction_params = config['prediction_params']\n",
    "\n",
    "num_epochs = prediction_params['num_epochs']\n",
    "lr = prediction_params['lr']\n",
    "bs = prediction_params['batch_size']\n",
    "num_frames = prediction_params['num_frames']\n",
    "loss_list_total = []\n",
    "fvd_list_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "104215c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './log/test-reconstruction-vox/prediction/prediction_png//video_frame_%04d.png':\n",
      "  Duration: 00:00:03.84, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 256x256, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x561a37f78640] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x561a37f78640] profile High, level 4.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x561a37f78640] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=20.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './log/test-reconstruction-vox/prediction/prediction_mp4//video_00.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 256x256, q=2-31, 60 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[mp4 @ 0x561a37f77480] Starting second pass: moving the moov atom to the beginning of the filex    \n",
      "frame=   97 fps=0.0 q=-1.0 Lsize=      52kB time=00:00:01.56 bitrate= 272.4kbits/s dup=1 drop=0 speed= 2.1x    \n",
      "video:50kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.942317%\n",
      "[libx264 @ 0x561a37f78640] frame I:1     Avg QP:23.17  size:  4238\n",
      "[libx264 @ 0x561a37f78640] frame P:25    Avg QP:23.65  size:  1252\n",
      "[libx264 @ 0x561a37f78640] frame B:71    Avg QP:28.42  size:   212\n",
      "[libx264 @ 0x561a37f78640] consecutive B-frames:  1.0%  4.1%  0.0% 94.8%\n",
      "[libx264 @ 0x561a37f78640] mb I  I16..4:  2.0% 72.7% 25.4%\n",
      "[libx264 @ 0x561a37f78640] mb P  I16..4:  0.0%  1.3%  0.3%  P16..4: 48.2% 24.1%  9.9%  0.0%  0.0%    skip:16.1%\n",
      "[libx264 @ 0x561a37f78640] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 38.0%  2.3%  0.3%  direct: 0.5%  skip:59.1%  L0:43.5% L1:54.3% BI: 2.1%\n",
      "[libx264 @ 0x561a37f78640] 8x8 transform intra:74.4% inter:81.6%\n",
      "[libx264 @ 0x561a37f78640] coded y,uvDC,uvAC intra: 88.7% 89.5% 39.9% inter: 10.5% 5.4% 0.0%\n",
      "[libx264 @ 0x561a37f78640] i16 v,h,dc,p: 43% 14%  0% 43%\n",
      "[libx264 @ 0x561a37f78640] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 20%  6%  7%  7%  9% 10%  9% 12%\n",
      "[libx264 @ 0x561a37f78640] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 13%  8%  7% 10% 11%  7%  9%  5%\n",
      "[libx264 @ 0x561a37f78640] i8c dc,h,v,p: 43% 22% 20% 15%\n",
      "[libx264 @ 0x561a37f78640] Weighted P-Frames: Y:8.0% UV:0.0%\n",
      "[libx264 @ 0x561a37f78640] ref P L0: 50.6% 20.1% 16.7% 11.2%  1.3%\n",
      "[libx264 @ 0x561a37f78640] ref B L0: 90.4%  6.4%  3.2%\n",
      "[libx264 @ 0x561a37f78640] ref B L1: 95.0%  5.0%\n",
      "[libx264 @ 0x561a37f78640] kb/s:250.52\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './log/test-reconstruction-vox/prediction/driving_png//video_frame_%04d.png':\n",
      "  Duration: 00:00:03.84, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 256x256, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55aa5d06b640] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55aa5d06b640] profile High, level 4.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55aa5d06b640] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=20.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './log/test-reconstruction-vox/prediction/driving_mp4//video_00.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 256x256, q=2-31, 60 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[mp4 @ 0x55aa5d06a480] Starting second pass: moving the moov atom to the beginning of the filex    \n",
      "frame=   97 fps=0.0 q=-1.0 Lsize=      77kB time=00:00:01.56 bitrate= 403.6kbits/s dup=1 drop=0 speed=2.78x    \n",
      "video:75kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.594453%\n",
      "[libx264 @ 0x55aa5d06b640] frame I:1     Avg QP:23.56  size:  4540\n",
      "[libx264 @ 0x55aa5d06b640] frame P:31    Avg QP:24.45  size:  1704\n",
      "[libx264 @ 0x55aa5d06b640] frame B:65    Avg QP:29.27  size:   292\n",
      "[libx264 @ 0x55aa5d06b640] consecutive B-frames:  4.1% 16.5%  9.3% 70.1%\n",
      "[libx264 @ 0x55aa5d06b640] mb I  I16..4:  1.2% 82.4% 16.4%\n",
      "[libx264 @ 0x55aa5d06b640] mb P  I16..4:  0.2%  3.2%  0.5%  P16..4: 45.4% 28.9% 11.8%  0.0%  0.0%    skip:10.0%\n",
      "[libx264 @ 0x55aa5d06b640] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 43.1%  5.0%  0.7%  direct: 0.6%  skip:50.5%  L0:42.4% L1:51.7% BI: 5.9%\n",
      "[libx264 @ 0x55aa5d06b640] 8x8 transform intra:83.0% inter:75.6%\n",
      "[libx264 @ 0x55aa5d06b640] coded y,uvDC,uvAC intra: 84.0% 84.4% 31.8% inter: 15.0% 12.4% 0.1%\n",
      "[libx264 @ 0x55aa5d06b640] i16 v,h,dc,p: 13% 33%  0% 53%\n",
      "[libx264 @ 0x55aa5d06b640] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 19%  9%  6%  8%  9% 11% 11% 11%\n",
      "[libx264 @ 0x55aa5d06b640] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 15% 11%  6% 10% 12%  8% 10%  7%\n",
      "[libx264 @ 0x55aa5d06b640] i8c dc,h,v,p: 46% 23% 18% 12%\n",
      "[libx264 @ 0x55aa5d06b640] Weighted P-Frames: Y:12.9% UV:0.0%\n",
      "[libx264 @ 0x55aa5d06b640] ref P L0: 64.2% 18.9% 13.5%  3.2%  0.2%\n",
      "[libx264 @ 0x55aa5d06b640] ref B L0: 93.9%  5.2%  0.9%\n",
      "[libx264 @ 0x55aa5d06b640] ref B L1: 98.3%  1.7%\n",
      "[libx264 @ 0x55aa5d06b640] kb/s:377.86\n",
      "1it [00:09,  9.14s/it]ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './log/test-reconstruction-vox/prediction/prediction_png//video_frame_%04d.png':\n",
      "  Duration: 00:00:13.44, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 256x256, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55cd2501fd40] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55cd2501fd40] profile High, level 4.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55cd2501fd40] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=20.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './log/test-reconstruction-vox/prediction/prediction_mp4//video_01.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 256x256, q=2-31, 60 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[mp4 @ 0x55cd2501eb80] Starting second pass: moving the moov atom to the beginning of the filex    \n",
      "frame=  337 fps=0.0 q=-1.0 Lsize=     177kB time=00:00:05.56 bitrate= 260.8kbits/s dup=1 drop=0 speed=15.3x    \n",
      "video:172kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.774757%\n",
      "[libx264 @ 0x55cd2501fd40] frame I:2     Avg QP:21.40  size:  5076\n",
      "[libx264 @ 0x55cd2501fd40] frame P:85    Avg QP:22.92  size:  1387\n",
      "[libx264 @ 0x55cd2501fd40] frame B:250   Avg QP:25.25  size:   191\n",
      "[libx264 @ 0x55cd2501fd40] consecutive B-frames:  0.6%  1.2%  0.9% 97.3%\n",
      "[libx264 @ 0x55cd2501fd40] mb I  I16..4:  4.3% 73.0% 22.7%\n",
      "[libx264 @ 0x55cd2501fd40] mb P  I16..4:  0.2%  1.7%  0.3%  P16..4: 42.8% 23.8% 10.8%  0.0%  0.0%    skip:20.5%\n",
      "[libx264 @ 0x55cd2501fd40] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 34.3%  1.8%  0.3%  direct: 0.5%  skip:63.1%  L0:39.4% L1:58.8% BI: 1.8%\n",
      "[libx264 @ 0x55cd2501fd40] 8x8 transform intra:75.7% inter:76.1%\n",
      "[libx264 @ 0x55cd2501fd40] coded y,uvDC,uvAC intra: 82.0% 83.3% 29.1% inter: 9.1% 4.5% 0.0%\n",
      "[libx264 @ 0x55cd2501fd40] i16 v,h,dc,p:  6% 13% 10% 71%\n",
      "[libx264 @ 0x55cd2501fd40] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 23%  9%  6% 10%  9% 12%  8% 12%\n",
      "[libx264 @ 0x55cd2501fd40] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 25%  9%  6%  9%  9% 12%  8%  8%\n",
      "[libx264 @ 0x55cd2501fd40] i8c dc,h,v,p: 49% 26% 11% 14%\n",
      "[libx264 @ 0x55cd2501fd40] Weighted P-Frames: Y:5.9% UV:0.0%\n",
      "[libx264 @ 0x55cd2501fd40] ref P L0: 51.0% 18.8% 18.4% 11.1%  0.6%\n",
      "[libx264 @ 0x55cd2501fd40] ref B L0: 89.2%  7.8%  3.1%\n",
      "[libx264 @ 0x55cd2501fd40] ref B L1: 94.6%  5.4%\n",
      "[libx264 @ 0x55cd2501fd40] kb/s:250.49\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './log/test-reconstruction-vox/prediction/driving_png//video_frame_%04d.png':\n",
      "  Duration: 00:00:13.44, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 256x256, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x564ea0829340] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x564ea0829340] profile High, level 4.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x564ea0829340] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=20.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './log/test-reconstruction-vox/prediction/driving_mp4//video_01.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 256x256, q=2-31, 60 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[mp4 @ 0x564ea0828440] Starting second pass: moving the moov atom to the beginning of the filex    \n",
      "frame=  337 fps=304 q=-1.0 Lsize=     256kB time=00:00:05.56 bitrate= 376.6kbits/s dup=1 drop=0 speed=5.03x    \n",
      "video:251kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.889103%\n",
      "[libx264 @ 0x564ea0829340] frame I:2     Avg QP:21.73  size:  6169\n",
      "[libx264 @ 0x564ea0829340] frame P:92    Avg QP:23.17  size:  1826\n",
      "[libx264 @ 0x564ea0829340] frame B:243   Avg QP:25.69  size:   313\n",
      "[libx264 @ 0x564ea0829340] consecutive B-frames:  1.2%  6.5%  4.5% 87.8%\n",
      "[libx264 @ 0x564ea0829340] mb I  I16..4:  2.1% 73.2% 24.6%\n",
      "[libx264 @ 0x564ea0829340] mb P  I16..4:  0.4%  2.8%  0.8%  P16..4: 45.6% 27.8% 12.7%  0.0%  0.0%    skip: 9.9%\n",
      "[libx264 @ 0x564ea0829340] mb B  I16..4:  0.0%  0.1%  0.0%  B16..8: 40.1%  4.6%  0.9%  direct: 0.7%  skip:53.6%  L0:40.1% L1:53.0% BI: 6.8%\n",
      "[libx264 @ 0x564ea0829340] 8x8 transform intra:71.3% inter:70.4%\n",
      "[libx264 @ 0x564ea0829340] coded y,uvDC,uvAC intra: 80.6% 87.8% 27.5% inter: 12.6% 12.9% 0.0%\n",
      "[libx264 @ 0x564ea0829340] i16 v,h,dc,p:  3% 13% 16% 69%\n",
      "[libx264 @ 0x564ea0829340] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 22% 12%  8%  9%  7% 10%  7% 14%\n",
      "[libx264 @ 0x564ea0829340] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 20% 14%  8%  9%  9% 11%  8%  8%\n",
      "[libx264 @ 0x564ea0829340] i8c dc,h,v,p: 50% 24% 14% 12%\n",
      "[libx264 @ 0x564ea0829340] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x564ea0829340] ref P L0: 60.5% 19.4% 14.8%  5.3%\n",
      "[libx264 @ 0x564ea0829340] ref B L0: 92.5%  5.4%  2.1%\n",
      "[libx264 @ 0x564ea0829340] ref B L1: 98.0%  2.0%\n",
      "[libx264 @ 0x564ea0829340] kb/s:365.37\n",
      "2it [00:36, 18.25s/it]\n"
     ]
    }
   ],
   "source": [
    "#########  FOMM+VAE ########\n",
    "mse_list = []\n",
    "for it, x in tqdm(enumerate(dataloader)):\n",
    "        if config['reconstruction_params']['num_videos'] is not None:\n",
    "            if it > config['reconstruction_params']['num_videos']:\n",
    "                break\n",
    "        if it>1:\n",
    "            break\n",
    "    \n",
    "        # Clear the PNG directories for each iteration of the outer loop\n",
    "        shutil.rmtree(pred_png_dir, ignore_errors=True)\n",
    "        os.makedirs(pred_png_dir)\n",
    "    \n",
    "        shutil.rmtree(driving_png_dir, ignore_errors=True)\n",
    "        os.makedirs(driving_png_dir)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            driving_frames = []\n",
    "            \n",
    "            ######## keypoints ########\n",
    "            kp_driving_video = test_video_unstd_list[it].reshape(-1,10,6)\n",
    "            kp_driving_video = torch.tensor(kp_driving_video)\n",
    "            kp_source = {\"value\":kp_driving_video[0,:,:2].reshape(1,10,2),\"jacobian\":kp_driving_video[0,:,2:].reshape(1,10,2,2)} # kp of the ith frame      \n",
    "        mse_list_frames = []\n",
    "        ##### Start generator\n",
    "        for i in range(((x['video'].shape[2])//frames)*frames): # cut the last <24 frames\n",
    "            source = x['video'][:, :, 0]\n",
    "            driving = x['video'][:, :, i]\n",
    "            kp_driving = {\"value\":kp_driving_video[i,:,:2],\"jacobian\":kp_driving_video[i,:,2:]} # kp of the ith frame\n",
    "            kp_driving['value'] = kp_driving['value'].reshape(1,10,2)\n",
    "            kp_driving['jacobian'] = kp_driving['jacobian'].reshape(1,10,2,2)\n",
    "            out = generator(source, kp_source=kp_source, kp_driving=kp_driving)\n",
    "            out['kp_source'] = kp_source\n",
    "            out['kp_driving'] = kp_driving\n",
    "            del out['sparse_deformed']\n",
    "            driving_frames.append(np.transpose(driving.data.cpu().numpy(),[0, 2, 3, 1])[0])\n",
    "            predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])\n",
    "            mse_list_frames.append(np.mean(np.square(driving_frames[i] - predictions[i])))\n",
    "#        predictions = np.concatenate(predictions, axis=1)\n",
    "\n",
    "        mse_list.append(np.mean(mse_list_frames))\n",
    "\n",
    "        #Save frames of predicted and driving videos as png's\n",
    "        save_frames_as_png(predictions, pred_png_dir)\n",
    "        save_frames_as_png(driving_frames,driving_png_dir)\n",
    "\n",
    "        #Convert frames into a y4m-formatted video\n",
    "#        convert_png_to_y4m(pred_png_dir, pred_y4m_dir, it)\n",
    "#        convert_png_to_y4m(driving_png_dir, driving_y4m_dir, it)\n",
    "        convert_png_to_mp4(pred_png_dir,pred_mp4_dir,it)\n",
    "        convert_png_to_mp4(driving_png_dir,driving_mp4_dir,it)\n",
    "\n",
    "        #Run VMAF on y4m-format videos\n",
    "#        run_vmaf(driving_y4m_dir+f'/video_{it:02d}.y4m',pred_y4m_dir+f'/video_{it:02d}.y4m',vae_vmaf_output+f'/vmaf_{it:02d}.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0efca-a8d0-4de3-ad0d-9bf84ca2a62d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
